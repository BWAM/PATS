---
title: "pats"
author: "NYSDEC"
date: "1/4/2024"
output: html_document
---

1.
Try using the function read_csv() from package readr to import the data into R. 
Average replicates by event_id using the dplyr functions group_by and summarize. Use the base R function mean in summarize.


```{r}
library(readr)
pats <- read_csv("patroons_macro_metrics.csv", 
                 col_types = cols(
  event_id = col_character(),
  river_mile = col_double(),
  sample_date = col_date(format = ""),
  project = col_character(),
  biosample_collection_method = col_character(),
  replicate = col_double(),
  group = col_character(),
  score_bioassessment_profile = col_double(),
  raw_richness = col_double(),
  score_richness = col_double(),
  raw_ept_richness = col_double(),
  score_ept_richness = col_double(),
  raw_hilsenhoff_biotic_index = col_double(),
  score_hilsenhoff_biotic_index = col_double(),
  raw_shannon_diversity = col_double(),
  score_shannon_diversity = col_double(),
  raw_percent_model_affinity = col_double(),
  score_percent_model_affinity = col_double(),
  raw_nutrient_biotic_index_phosphorus = col_double(),
  score_nutrient_biotic_index_phosphorus = col_double(),
  raw_non_chiro_oligo_richness = col_double(),
  score_non_chiro_oligo_richness = col_double(),
  raw_percent_dominance_3 = col_double(),
  score_percent_dominance_3 = col_double()
)) %>%
  filter(sample_date>"2018-01-01")

library(dplyr)
pats_mean <- pats %>%
  group_by(event_id, river_mile, sample_date) %>%
  summarize(avg_replicate = mean(score_bioassessment_profile, na.rm = TRUE)) %>% 
  ungroup() 




```

2.
Add a new column using the dplyr function mutate with case_when() that categorizes the data into:
 "above" , "within", "below" using river_mile. You probably need something like "above","within1", "within2", "below1", "below2". I think it would be reasonable to try lumping the odd 2021 sites with their closest counter part.
"before" and "after" based on sample date.
```{r}
#Please replace lower_bound and upper_bound with the actual values that define your categories. Also, replace date_condition with the actual date that separates “before” and “after”.
library(dplyr)

pats_cat <- pats_mean%>%
  mutate(
    river_mile_category = case_when(
      river_mile == 0.5 ~ "below1",
      river_mile == 1.3 ~ "below2",
      river_mile == 1.5 ~ "within1",
      river_mile == 1.7 ~ "within2",
      river_mile == 1.8 ~ "above", 
      TRUE~"ERROR"
    ),
    sample_date_category = case_when(
      sample_date < "2019-01-01" ~ "before",
      sample_date >= "2019-01-01" ~ "after",
      TRUE~"ERROR"
    )
  )

```

3. 
use the tidyr function, pivot_wider, to get the site categories "above", "within", "below" to represent individual columns by date (rows).
Use dplyr mutate to find the difference between sites. For example, mutate(above_below_diff = above - below).
```{r}
library(tidyr)
pats_wide <- pats_cat %>% 
  select(-event_id, -river_mile) %>% 
  pivot_wider(
    names_from = river_mile_category, values_from = avg_replicate
  )

#check for difference between above and below in the two time periods 
#above-below before and after
```

4.
Use ggpubr to plot the data: Plot Paired Data — ggpaired • ggpubr (datanovia.com)
use the Wilcoxon Rank Sum test (wilcox.test()) to compare the two periods. If more than one difference is evaluated, use kruskal Wallis test and then, if kruskal wallis is significant, use post hoc wilcoxon test or dunns test.

```{r}

```
